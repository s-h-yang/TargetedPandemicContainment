{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from random import sample\n",
    "import csv\n",
    "from func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load county information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/facebook-counties/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = []\n",
    "state = []\n",
    "with open(path+'facebook-county-friendship-metadata.csv', newline='') as csvfile:\n",
    "    meta_data = csv.reader(csvfile, delimiter='\\t', quotechar='|')\n",
    "    for row in meta_data:\n",
    "        populations.append(int(row[0]))\n",
    "        state.append(row[2])\n",
    "\n",
    "labels = []\n",
    "with open(path+'facebook-county-friendship.labels', newline='') as csvfile:\n",
    "    meta_data = csv.reader(csvfile, delimiter='\\t', quotechar='|')\n",
    "    for row in meta_data:\n",
    "        labels.append(row[0])\n",
    "        \n",
    "fips = []\n",
    "with open(path+'county-info.csv', newline='') as csvfile:\n",
    "    meta_data = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    next(meta_data)\n",
    "    for row in meta_data:\n",
    "        fips.append(row[0])\n",
    "        \n",
    "xy = np.loadtxt('../data/facebook-counties/facebook-county-friendship.xy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read graph\n",
    "#### We are going to remove the following nodes:\n",
    "- counties in Hawaii and Alaska\n",
    "- six disconnected counties in Virginia\n",
    "- irregular node representing Loving, Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_graphml('../data/facebook-counties/facebook-county.graphml', node_type=int)\n",
    "\n",
    "removed = []\n",
    "disconnected = [\"Covington, VA\", \"Emporia, VA\", \"Fairfax, VA\", \n",
    "                \"Lexington, VA\", \"Manassas Park, VA\", \"Martinsville, VA\"]\n",
    "irregular = [\"Loving, TX\"]\n",
    "for i in range(G.number_of_nodes()):\n",
    "    if state[i] == 'HI' or state[i] == 'AK':\n",
    "        removed.append(i+1)\n",
    "    elif labels[i] in disconnected:\n",
    "        print(labels[i])\n",
    "        removed.append(i+1)\n",
    "    elif labels[i] in irregular:\n",
    "        print(labels[i])\n",
    "        removed.append(i+1)\n",
    "        \n",
    "G.remove_nodes_from(removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relabel nodes from 1 to n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = G.number_of_nodes()\n",
    "mapping = dict(zip(G, range(1, n+1)))\n",
    "G = nx.relabel_nodes(G, mapping)\n",
    "map_to_original = dict((val,key-1) for key,val in mapping.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove edges that are longer than 500 miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = 0\n",
    "for u,v in G.edges():\n",
    "    if distance(xy[map_to_original[u]][::-1], xy[map_to_original[v]][::-1]).miles > 500:\n",
    "        G.remove_edge(u,v)\n",
    "        ct += 1\n",
    "\n",
    "print(f'Number of edges removed: {ct}')\n",
    "print(f'Number of edges in total: {G.number_of_edges()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = dict((i, xy[map_to_original[i],:]) for i in range(1,n+1))\n",
    "nx.draw(G, pos, node_size=0, width=.1, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute betweenness measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path_betweenness = nx.edge_betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_flow_betweenness = nx.edge_current_flow_betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from julia.api import Julia\n",
    "jl = Julia(compiled_modules=False)\n",
    "from julia import Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main.include(\"../local_flow_betweenness.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local50_betweenness = Main.local_flow_betweenness(np.array(G.nodes()), list(G.edges()), locality_index=.5)\n",
    "local10_betweenness = Main.local_flow_betweenness(np.array(G.nodes()), list(G.edges()), locality_index=.1)\n",
    "local02_betweenness = Main.local_flow_betweenness(np.array(G.nodes()), list(G.edges()), locality_index=.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervention and simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main.include(\"../utils.jl\");\n",
    "Main.include(\"../networkSEIR.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_population = 0\n",
    "for i in G.nodes():\n",
    "    total_population += populations[map_to_original[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = (nx.adjacency_matrix(G) + sp.sparse.eye(G.number_of_nodes())).tocsc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1a: 85% final size, random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=0.0315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that $\\beta$ is set appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions\n",
    "S_0 = np.zeros(n)\n",
    "E_0 = np.zeros(n)\n",
    "I_0 = np.zeros(n)\n",
    "R_0 = np.zeros(n)\n",
    "for i in range(n):\n",
    "    S_0[i] = populations[map_to_original[i+1]]\n",
    "\n",
    "# the following lines set up random initialization\n",
    "for i in sample(range(n),31):\n",
    "    E_0[i] = 0\n",
    "    I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "    S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\n",
    "# the following lines set up cluster initialization\n",
    "\"\"\"\n",
    "for i in initial_cluster:\n",
    "    E_0[i] = 0\n",
    "    I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "    S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\"\"\"\n",
    "\n",
    "# the following lines set up NY initialization\n",
    "\"\"\"\n",
    "for i in range(n):\n",
    "    county_no = map_to_original[i+1]\n",
    "    if labels[county_no] == 'New York, NY':\n",
    "        E_0[i] = 0\n",
    "        I_0[i] = populations[county_no] * .001\n",
    "        S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\"\"\"\n",
    "\n",
    "# the following lines set up LA initialization\n",
    "\"\"\"\n",
    "for i in range(n):\n",
    "    county_no = map_to_original[i+1]\n",
    "    if labels[county_no] == 'Los Angeles, CA':\n",
    "        E_0[i] = 0\n",
    "        I_0[i] = populations[county_no] * .001\n",
    "        S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\"\"\"\n",
    "\n",
    "# the following lines set up Chicago initialization\n",
    "\"\"\"\n",
    "for i in range(n):\n",
    "    county_no = map_to_original[i+1]\n",
    "    if labels[county_no] == 'Cook, IL':\n",
    "        E_0[i] = 0\n",
    "        I_0[i] = populations[county_no] * .001\n",
    "        S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\"\"\"\n",
    "    \n",
    "ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "\n",
    "# time span\n",
    "t_end = 400.\n",
    "t_span = (0.,t_end)\n",
    "\n",
    "sol = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "print(f'This should be around 0.85: {get_total_active_cases(sol)/total_population:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "sum_s_ni, sum_e_ni, sum_i_ni, sum_r_ni = get_data_for_plotting(sol)\n",
    "t_int = np.linspace(0, int(t_end), num=int(t_end)+1)\n",
    "plt.plot(t_int,(sum_e_ni+sum_i_ni)/total_population, label='NI', linestyle='-', color='dimgray', linewidth=3, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample epidemic curve: random initialization, 25% intervention, no delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = .25\n",
    "reduced_weight = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ui = ((1-(1-reduced_weight)*perc)*nx.adjacency_matrix(G) + sp.sparse.eye(G.number_of_nodes())).tocsc()\n",
    "A_hd = create_weighted_adjacency_from_degree_dist(G, perc, weight=reduced_weight)\n",
    "A_eg = create_weighted_adjacency_from_node_betweenness(G, eigenvector_centrality, perc, weight=reduced_weight)\n",
    "A_sp = create_weighted_adjacency_from_edge_betweenness(G, shortest_path_betweenness, perc, weight=reduced_weight)\n",
    "A_rw = create_weighted_adjacency_from_edge_betweenness(G, current_flow_betweenness, perc, weight=reduced_weight)\n",
    "A_lf50 = create_weighted_adjacency_from_edge_betweenness(G, local50_betweenness, perc, weight=reduced_weight)\n",
    "A_lf10 = create_weighted_adjacency_from_edge_betweenness(G, local10_betweenness, perc, weight=reduced_weight)\n",
    "A_lf02 = create_weighted_adjacency_from_edge_betweenness(G, local02_betweenness, perc, weight=reduced_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time span\n",
    "t_end = 200.\n",
    "t_span = (0., t_end)\n",
    "\n",
    "# initial conditions\n",
    "n = G.number_of_nodes()\n",
    "S_0 = np.zeros(n)\n",
    "E_0 = np.zeros(n)\n",
    "I_0 = np.zeros(n)\n",
    "R_0 = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    S_0[i] = populations[map_to_original[i+1]]\n",
    "\n",
    "# the following lines set up random initialization\n",
    "for i in sample(range(n),31):\n",
    "    E_0[i] = 0\n",
    "    I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "    S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\n",
    "ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "\n",
    "# simulation\n",
    "sol_ni = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "sol_ui = Main.run_network_seir(Main.scipyCSC_to_julia(A_ui), ini_cond, t_span, beta=beta)\n",
    "sol_hd = Main.run_network_seir(Main.scipyCSC_to_julia(A_hd), ini_cond, t_span, beta=beta)\n",
    "sol_eg = Main.run_network_seir(Main.scipyCSC_to_julia(A_eg), ini_cond, t_span, beta=beta)\n",
    "sol_sp = Main.run_network_seir(Main.scipyCSC_to_julia(A_sp), ini_cond, t_span, beta=beta)\n",
    "sol_rw = Main.run_network_seir(Main.scipyCSC_to_julia(A_rw), ini_cond, t_span, beta=beta)\n",
    "sol_lf50 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf50), ini_cond, t_span, beta=beta)\n",
    "sol_lf10 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf10), ini_cond, t_span, beta=beta)\n",
    "sol_lf02 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf02), ini_cond, t_span, beta=beta)\n",
    "\n",
    "# get curves and make plot\n",
    "sum_s_ni, sum_e_ni, sum_i_ni, sum_r_ni = get_data_for_plotting(sol_ni)\n",
    "sum_s_ui, sum_e_ui, sum_i_ui, sum_r_ui = get_data_for_plotting(sol_ui)\n",
    "sum_s_hd, sum_e_hd, sum_i_hd, sum_r_hd = get_data_for_plotting(sol_hd)\n",
    "sum_s_eg, sum_e_eg, sum_i_eg, sum_r_eg = get_data_for_plotting(sol_eg)\n",
    "sum_s_sp, sum_e_sp, sum_i_sp, sum_r_sp = get_data_for_plotting(sol_sp)\n",
    "sum_s_rw, sum_e_rw, sum_i_rw, sum_r_rw = get_data_for_plotting(sol_rw)\n",
    "sum_s_lf50, sum_e_lf50, sum_i_lf50, sum_r_lf50 = get_data_for_plotting(sol_lf50)\n",
    "sum_s_lf10, sum_e_lf10, sum_i_lf10, sum_r_lf10 = get_data_for_plotting(sol_lf10)\n",
    "sum_s_lf02, sum_e_lf02, sum_i_lf02, sum_r_lf02 = get_data_for_plotting(sol_lf02)\n",
    "\n",
    "t_int = np.linspace(0, int(t_end), num=int(t_end)+1)\n",
    "\n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(t_int,(sum_e_ni+sum_i_ni)/total_population, label='NI', linestyle='-', color='dimgray', linewidth=3, alpha=1)\n",
    "plt.plot(t_int,(sum_e_ui+sum_i_ui)/total_population, label='UI', linestyle=(0,(5,5)), color='k', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_eg+sum_i_eg)/total_population, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_hd+sum_i_hd)/total_population, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_sp+sum_i_sp)/total_population, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_rw+sum_i_rw)/total_population, label='CF', linestyle='dashed', color='tab:green', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf50+sum_i_lf50)/total_population, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf10+sum_i_lf10)/total_population, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf02+sum_i_lf02)/total_population, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=4)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks(size=18)\n",
    "plt.yticks((.0, .1), size=18)\n",
    "plt.xlabel('Day', fontsize=22)\n",
    "plt.ylabel('Active Cases',fontsize=22)\n",
    "plt.savefig(\"facebook_curves_randinit_85.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation for interventions that start on day 0, random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_weight = .1\n",
    "target_perc = [.05, .1, .15, .2, .25, .3, .35, .4, .45, .5]\n",
    "num_scenarios = len(target_perc)\n",
    "num_trials = 50\n",
    "\n",
    "maxCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "\n",
    "for k in range(num_scenarios):\n",
    "    \n",
    "    perc = target_perc[k]\n",
    "    A_ui = ((1-(1-reduced_weight)*perc)*nx.adjacency_matrix(G) + sp.sparse.eye(G.number_of_nodes())).tocsc()\n",
    "    A_hd = create_weighted_adjacency_from_degree_dist(G, perc, weight=reduced_weight)\n",
    "    A_eg = create_weighted_adjacency_from_node_betweenness(G, eigenvector_centrality, perc, weight=reduced_weight)\n",
    "    A_sp = create_weighted_adjacency_from_edge_betweenness(G, shortest_path_betweenness, perc, weight=reduced_weight)\n",
    "    A_rw = create_weighted_adjacency_from_edge_betweenness(G, current_flow_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf50 = create_weighted_adjacency_from_edge_betweenness(G, local50_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf10 = create_weighted_adjacency_from_edge_betweenness(G, local10_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf02 = create_weighted_adjacency_from_edge_betweenness(G, local02_betweenness, perc, weight=reduced_weight)\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        \n",
    "        print(f'perc = {perc:.2f}, trial {trial+1:d} of {num_trials:d}', end=\"\\n\")\n",
    "    \n",
    "        S_0 = np.zeros(n)\n",
    "        E_0 = np.zeros(n)\n",
    "        I_0 = np.zeros(n)\n",
    "        R_0 = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            S_0[i] = populations[map_to_original[i+1]]\n",
    "\n",
    "        for i in sample(range(n),31):\n",
    "            E_0[i] = 0\n",
    "            I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "            S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\n",
    "        ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "        t_span = (0.,1000.)\n",
    "        \n",
    "        sol_ni = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "        sol_ui = Main.run_network_seir(Main.scipyCSC_to_julia(A_ui), ini_cond, t_span, beta=beta)\n",
    "        sol_hd = Main.run_network_seir(Main.scipyCSC_to_julia(A_hd), ini_cond, t_span, beta=beta)\n",
    "        sol_eg = Main.run_network_seir(Main.scipyCSC_to_julia(A_eg), ini_cond, t_span, beta=beta)\n",
    "        sol_sp = Main.run_network_seir(Main.scipyCSC_to_julia(A_sp), ini_cond, t_span, beta=beta)\n",
    "        sol_rw = Main.run_network_seir(Main.scipyCSC_to_julia(A_rw), ini_cond, t_span, beta=beta)\n",
    "        sol_lf50 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf50), ini_cond, t_span, beta=beta)\n",
    "        sol_lf10 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf10), ini_cond, t_span, beta=beta)\n",
    "        sol_lf02 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf02), ini_cond, t_span, beta=beta) \n",
    "        maxCases_ni[trial,k] = get_max_active_cases(sol_ni)\n",
    "        maxCases_ui[trial,k] = get_max_active_cases(sol_ui)\n",
    "        maxCases_hd[trial,k] = get_max_active_cases(sol_hd)\n",
    "        maxCases_eg[trial,k] = get_max_active_cases(sol_eg)\n",
    "        maxCases_sp[trial,k] = get_max_active_cases(sol_sp)\n",
    "        maxCases_rw[trial,k] = get_max_active_cases(sol_rw)\n",
    "        maxCases_lf50[trial,k] = get_max_active_cases(sol_lf50)\n",
    "        maxCases_lf10[trial,k] = get_max_active_cases(sol_lf10)\n",
    "        maxCases_lf02[trial,k] = get_max_active_cases(sol_lf02)\n",
    "        totalCases_ni[trial,k] = get_total_active_cases(sol_ni)\n",
    "        totalCases_ui[trial,k] = get_total_active_cases(sol_ui)\n",
    "        totalCases_hd[trial,k] = get_total_active_cases(sol_hd)\n",
    "        totalCases_eg[trial,k] = get_total_active_cases(sol_eg)\n",
    "        totalCases_sp[trial,k] = get_total_active_cases(sol_sp)\n",
    "        totalCases_rw[trial,k] = get_total_active_cases(sol_rw)\n",
    "        totalCases_lf50[trial,k] = get_total_active_cases(sol_lf50)\n",
    "        totalCases_lf10[trial,k] = get_total_active_cases(sol_lf10)\n",
    "        totalCases_lf02[trial,k] = get_total_active_cases(sol_lf02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCases_ni_mean = np.mean(maxCases_ni/total_population, axis=0)\n",
    "maxCases_ui_mean = np.mean(maxCases_ui/total_population, axis=0)\n",
    "maxCases_hd_mean = np.mean(maxCases_hd/total_population, axis=0)\n",
    "maxCases_eg_mean = np.mean(maxCases_eg/total_population, axis=0)\n",
    "maxCases_sp_mean = np.mean(maxCases_sp/total_population, axis=0)\n",
    "maxCases_rw_mean = np.mean(maxCases_rw/total_population, axis=0)\n",
    "maxCases_lf50_mean = np.mean(maxCases_lf50/total_population, axis=0)\n",
    "maxCases_lf10_mean = np.mean(maxCases_lf10/total_population, axis=0)\n",
    "maxCases_lf02_mean = np.mean(maxCases_lf02/total_population, axis=0)\n",
    "totalCases_ni_mean = np.mean(totalCases_ni/total_population, axis=0)\n",
    "totalCases_ui_mean = np.mean(totalCases_ui/total_population, axis=0)\n",
    "totalCases_hd_mean = np.mean(totalCases_hd/total_population, axis=0)\n",
    "totalCases_eg_mean = np.mean(totalCases_eg/total_population, axis=0)\n",
    "totalCases_sp_mean = np.mean(totalCases_sp/total_population, axis=0)\n",
    "totalCases_rw_mean = np.mean(totalCases_rw/total_population, axis=0)\n",
    "totalCases_lf50_mean = np.mean(totalCases_lf50/total_population, axis=0)\n",
    "totalCases_lf10_mean = np.mean(totalCases_lf10/total_population, axis=0)\n",
    "totalCases_lf02_mean = np.mean(totalCases_lf02/total_population, axis=0)\n",
    "\n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, maxCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.1, .2, .3, .4, .5), ('$10\\%$', '$20\\%$', '$30\\%$', '$40\\%$', '$50\\%$'), color='k', size=18)\n",
    "plt.yticks((.1, .2), size=18)\n",
    "plt.xlabel('Percentage of Targeted Edges', fontsize=22)\n",
    "plt.ylabel('Epidemic Peak',fontsize=22)\n",
    "plt.savefig(\"facebook_epipeak_randinit_85.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()\n",
    "                                      \n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, totalCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.1, .2, .3, .4, .5), ('$10\\%$', '$20\\%$', '$30\\%$', '$40\\%$', '$50\\%$'), color='k', size=18)\n",
    "plt.yticks(size=18)\n",
    "plt.xlabel('Percentage of Targeted Edges', fontsize=22)\n",
    "plt.ylabel('Final Epidemic Size',fontsize=22)\n",
    "plt.savefig(\"facebook_episize_randinit_85.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1b: 85% final size, cluster initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states = ['NH', 'ME', 'MA', 'CT', 'VT', 'RI']\n",
    "initial_cluster = []\n",
    "for i in G.nodes():\n",
    "    if state[map_to_original[i]] in initial_states:\n",
    "        initial_cluster.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=0.0315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that $\\beta$ is set appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions\n",
    "S_0 = np.zeros(n)\n",
    "E_0 = np.zeros(n)\n",
    "I_0 = np.zeros(n)\n",
    "R_0 = np.zeros(n)\n",
    "for i in range(n):\n",
    "    S_0[i] = populations[map_to_original[i+1]]  \n",
    "\n",
    "# the following lines set up cluster initialization\n",
    "for i in initial_cluster:\n",
    "    E_0[i] = 0\n",
    "    I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "    S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "    \n",
    "ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "\n",
    "# time span\n",
    "t_end = 400.\n",
    "t_span = (0.,t_end)\n",
    "\n",
    "sol = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "print(f'This should be around 0.85: {get_total_active_cases(sol)/total_population:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for plotting\n",
    "sum_S, sum_E, sum_I, sum_R = get_data_for_plotting(sol)\n",
    "with open(\"facebookcounty_curves.txt\", \"w\") as f:\n",
    "    for i in range(len(sum_S)):\n",
    "        f.write(f\"{sum_S[i]/total_population:.6f}\\t{sum_E[i]/total_population:.6f}\\t{sum_I[i]/total_population:.6f}\\t{sum_R[i]/total_population:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "sum_s_ni, sum_e_ni, sum_i_ni, sum_r_ni = get_data_for_plotting(sol)\n",
    "t_int = np.linspace(0, int(t_end), num=int(t_end)+1)\n",
    "plt.plot(t_int,(sum_e_ni+sum_i_ni)/total_population, label='NI', linestyle='-', color='dimgray', linewidth=3, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample epidemic curve: cluster initialization, no delay, 25% intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = .25\n",
    "reduced_weight = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ui = ((1-(1-reduced_weight)*perc)*nx.adjacency_matrix(G) + sp.sparse.eye(G.number_of_nodes())).tocsc()\n",
    "A_hd = create_weighted_adjacency_from_degree_dist(G, perc, weight=reduced_weight)\n",
    "A_eg = create_weighted_adjacency_from_node_betweenness(G, eigenvector_centrality, perc, weight=reduced_weight)\n",
    "A_sp = create_weighted_adjacency_from_edge_betweenness(G, shortest_path_betweenness, perc, weight=reduced_weight)\n",
    "A_rw = create_weighted_adjacency_from_edge_betweenness(G, current_flow_betweenness, perc, weight=reduced_weight)\n",
    "A_lf50 = create_weighted_adjacency_from_edge_betweenness(G, local50_betweenness, perc, weight=reduced_weight)\n",
    "A_lf10 = create_weighted_adjacency_from_edge_betweenness(G, local10_betweenness, perc, weight=reduced_weight)\n",
    "A_lf02 = create_weighted_adjacency_from_edge_betweenness(G, local02_betweenness, perc, weight=reduced_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted epidemic curve: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time span\n",
    "t_end = 400.\n",
    "t_span = (0., t_end)\n",
    "\n",
    "# initial conditions\n",
    "n = G.number_of_nodes()\n",
    "S_0 = np.zeros(n)\n",
    "E_0 = np.zeros(n)\n",
    "I_0 = np.zeros(n)\n",
    "R_0 = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    S_0[i] = populations[map_to_original[i+1]]\n",
    "    \n",
    "# the following lines set up cluster initialization\n",
    "for i in initial_cluster:\n",
    "    E_0[i] = 0\n",
    "    I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "    S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\n",
    "ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "\n",
    "# simulation\n",
    "sol_ni = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "sol_ui = Main.run_network_seir(Main.scipyCSC_to_julia(A_ui), ini_cond, t_span, beta=beta)\n",
    "sol_hd = Main.run_network_seir(Main.scipyCSC_to_julia(A_hd), ini_cond, t_span, beta=beta)\n",
    "sol_eg = Main.run_network_seir(Main.scipyCSC_to_julia(A_eg), ini_cond, t_span, beta=beta)\n",
    "sol_sp = Main.run_network_seir(Main.scipyCSC_to_julia(A_sp), ini_cond, t_span, beta=beta)\n",
    "sol_rw = Main.run_network_seir(Main.scipyCSC_to_julia(A_rw), ini_cond, t_span, beta=beta)\n",
    "sol_lf50 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf50), ini_cond, t_span, beta=beta)\n",
    "sol_lf10 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf10), ini_cond, t_span, beta=beta)\n",
    "sol_lf02 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf02), ini_cond, t_span, beta=beta)\n",
    "\n",
    "# get curves and make plot\n",
    "sum_s_ni, sum_e_ni, sum_i_ni, sum_r_ni = get_data_for_plotting(sol_ni)\n",
    "sum_s_ui, sum_e_ui, sum_i_ui, sum_r_ui = get_data_for_plotting(sol_ui)\n",
    "sum_s_hd, sum_e_hd, sum_i_hd, sum_r_hd = get_data_for_plotting(sol_hd)\n",
    "sum_s_eg, sum_e_eg, sum_i_eg, sum_r_eg = get_data_for_plotting(sol_eg)\n",
    "sum_s_sp, sum_e_sp, sum_i_sp, sum_r_sp = get_data_for_plotting(sol_sp)\n",
    "sum_s_rw, sum_e_rw, sum_i_rw, sum_r_rw = get_data_for_plotting(sol_rw)\n",
    "sum_s_lf50, sum_e_lf50, sum_i_lf50, sum_r_lf50 = get_data_for_plotting(sol_lf50)\n",
    "sum_s_lf10, sum_e_lf10, sum_i_lf10, sum_r_lf10 = get_data_for_plotting(sol_lf10)\n",
    "sum_s_lf02, sum_e_lf02, sum_i_lf02, sum_r_lf02 = get_data_for_plotting(sol_lf02)\n",
    "\n",
    "t_int = np.linspace(0, int(t_end), num=int(t_end)+1)\n",
    "\n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(t_int,(sum_e_ni+sum_i_ni)/total_population, label='NI', linestyle='-', color='dimgray', linewidth=3, alpha=1)\n",
    "plt.plot(t_int,(sum_e_ui+sum_i_ui)/total_population, label='UI', linestyle=(0,(5,5)), color='k', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_eg+sum_i_eg)/total_population, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_hd+sum_i_hd)/total_population, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_sp+sum_i_sp)/total_population, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_rw+sum_i_rw)/total_population, label='CF', linestyle='dashed', color='tab:green', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf50+sum_i_lf50)/total_population, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf10+sum_i_lf10)/total_population, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf02+sum_i_lf02)/total_population, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=4)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks(size=18)\n",
    "plt.yticks(size=18)\n",
    "plt.xlabel('Day', fontsize=22)\n",
    "plt.ylabel('Active Cases',fontsize=22)\n",
    "plt.savefig(\"facebook_curves_cluster_85.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation for interventions that start on day 0, cluster initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_weight = .1\n",
    "target_perc = [.05, .1, .15, .2, .25, .3, .35, .4, .45, .5]\n",
    "num_scenarios = len(target_perc)\n",
    "num_trials = 50\n",
    "\n",
    "maxCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "\n",
    "for k in range(num_scenarios):\n",
    "    \n",
    "    perc = target_perc[k]\n",
    "    A_ui = ((1-(1-reduced_weight)*perc)*nx.adjacency_matrix(G) + sp.sparse.eye(G.number_of_nodes())).tocsc()\n",
    "    A_hd = create_weighted_adjacency_from_degree_dist(G, perc, weight=reduced_weight)\n",
    "    A_eg = create_weighted_adjacency_from_node_betweenness(G, eigenvector_centrality, perc, weight=reduced_weight)\n",
    "    A_sp = create_weighted_adjacency_from_edge_betweenness(G, shortest_path_betweenness, perc, weight=reduced_weight)\n",
    "    A_rw = create_weighted_adjacency_from_edge_betweenness(G, current_flow_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf50 = create_weighted_adjacency_from_edge_betweenness(G, local50_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf10 = create_weighted_adjacency_from_edge_betweenness(G, local10_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf02 = create_weighted_adjacency_from_edge_betweenness(G, local02_betweenness, perc, weight=reduced_weight)\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        \n",
    "        print(f'perc = {perc:.2f}, trial {trial+1:d} of {num_trials:d}', end=\"\\n\")\n",
    "    \n",
    "        S_0 = np.zeros(n)\n",
    "        E_0 = np.zeros(n)\n",
    "        I_0 = np.zeros(n)\n",
    "        R_0 = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            S_0[i] = populations[map_to_original[i+1]]\n",
    "                \n",
    "        # the following lines set up cluster initialization\n",
    "        for i in initial_cluster:\n",
    "            E_0[i] = 0\n",
    "            I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "            S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "        \n",
    "        ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "        t_span = (0.,1200.)\n",
    "        \n",
    "        sol_ni = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "        sol_ui = Main.run_network_seir(Main.scipyCSC_to_julia(A_ui), ini_cond, t_span, beta=beta)\n",
    "        sol_hd = Main.run_network_seir(Main.scipyCSC_to_julia(A_hd), ini_cond, t_span, beta=beta)\n",
    "        sol_eg = Main.run_network_seir(Main.scipyCSC_to_julia(A_eg), ini_cond, t_span, beta=beta)\n",
    "        sol_sp = Main.run_network_seir(Main.scipyCSC_to_julia(A_sp), ini_cond, t_span, beta=beta)\n",
    "        sol_rw = Main.run_network_seir(Main.scipyCSC_to_julia(A_rw), ini_cond, t_span, beta=beta)\n",
    "        sol_lf50 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf50), ini_cond, t_span, beta=beta)\n",
    "        sol_lf10 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf10), ini_cond, t_span, beta=beta)\n",
    "        sol_lf02 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf02), ini_cond, t_span, beta=beta) \n",
    "        maxCases_ni[trial,k] = get_max_active_cases(sol_ni)\n",
    "        maxCases_ui[trial,k] = get_max_active_cases(sol_ui)\n",
    "        maxCases_hd[trial,k] = get_max_active_cases(sol_hd)\n",
    "        maxCases_eg[trial,k] = get_max_active_cases(sol_eg)\n",
    "        maxCases_sp[trial,k] = get_max_active_cases(sol_sp)\n",
    "        maxCases_rw[trial,k] = get_max_active_cases(sol_rw)\n",
    "        maxCases_lf50[trial,k] = get_max_active_cases(sol_lf50)\n",
    "        maxCases_lf10[trial,k] = get_max_active_cases(sol_lf10)\n",
    "        maxCases_lf02[trial,k] = get_max_active_cases(sol_lf02)\n",
    "        totalCases_ni[trial,k] = get_total_active_cases(sol_ni)\n",
    "        totalCases_ui[trial,k] = get_total_active_cases(sol_ui)\n",
    "        totalCases_hd[trial,k] = get_total_active_cases(sol_hd)\n",
    "        totalCases_eg[trial,k] = get_total_active_cases(sol_eg)\n",
    "        totalCases_sp[trial,k] = get_total_active_cases(sol_sp)\n",
    "        totalCases_rw[trial,k] = get_total_active_cases(sol_rw)\n",
    "        totalCases_lf50[trial,k] = get_total_active_cases(sol_lf50)\n",
    "        totalCases_lf10[trial,k] = get_total_active_cases(sol_lf10)\n",
    "        totalCases_lf02[trial,k] = get_total_active_cases(sol_lf02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCases_ni_mean = np.mean(maxCases_ni/total_population, axis=0)\n",
    "maxCases_ui_mean = np.mean(maxCases_ui/total_population, axis=0)\n",
    "maxCases_hd_mean = np.mean(maxCases_hd/total_population, axis=0)\n",
    "maxCases_eg_mean = np.mean(maxCases_eg/total_population, axis=0)\n",
    "maxCases_sp_mean = np.mean(maxCases_sp/total_population, axis=0)\n",
    "maxCases_rw_mean = np.mean(maxCases_rw/total_population, axis=0)\n",
    "maxCases_lf50_mean = np.mean(maxCases_lf50/total_population, axis=0)\n",
    "maxCases_lf10_mean = np.mean(maxCases_lf10/total_population, axis=0)\n",
    "maxCases_lf02_mean = np.mean(maxCases_lf02/total_population, axis=0)\n",
    "totalCases_ni_mean = np.mean(totalCases_ni/total_population, axis=0)\n",
    "totalCases_ui_mean = np.mean(totalCases_ui/total_population, axis=0)\n",
    "totalCases_hd_mean = np.mean(totalCases_hd/total_population, axis=0)\n",
    "totalCases_eg_mean = np.mean(totalCases_eg/total_population, axis=0)\n",
    "totalCases_sp_mean = np.mean(totalCases_sp/total_population, axis=0)\n",
    "totalCases_rw_mean = np.mean(totalCases_rw/total_population, axis=0)\n",
    "totalCases_lf50_mean = np.mean(totalCases_lf50/total_population, axis=0)\n",
    "totalCases_lf10_mean = np.mean(totalCases_lf10/total_population, axis=0)\n",
    "totalCases_lf02_mean = np.mean(totalCases_lf02/total_population, axis=0)\n",
    "\n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, maxCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.1, .2, .3, .4, .5), ('$10\\%$', '$20\\%$', '$30\\%$', '$40\\%$', '$50\\%$'), color='k', size=18)\n",
    "plt.yticks(size=18)\n",
    "plt.xlabel('Percentage of Targeted Edges', fontsize=22)\n",
    "plt.ylabel('Epidemic Peak',fontsize=22)\n",
    "plt.savefig(\"facebook_epipeak_cluster_85.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()\n",
    "                                      \n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, totalCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.1, .2, .3, .4, .5), ('$10\\%$', '$20\\%$', '$30\\%$', '$40\\%$', '$50\\%$'), color='k', size=18)\n",
    "plt.yticks(size=18)\n",
    "plt.xlabel('Percentage of Targeted Edges', fontsize=22)\n",
    "plt.ylabel('Final Epidemic Size',fontsize=22)\n",
    "plt.savefig(\"facebook_episize_cluster_85.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1c: 85% final size, random initialization + delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=0.0315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that $\\beta$ is set appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions\n",
    "S_0 = np.zeros(n)\n",
    "E_0 = np.zeros(n)\n",
    "I_0 = np.zeros(n)\n",
    "R_0 = np.zeros(n)\n",
    "for i in range(n):\n",
    "    S_0[i] = populations[map_to_original[i+1]]\n",
    "\n",
    "for i in sample(range(n),31):\n",
    "    E_0[i] = 0\n",
    "    I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "    S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "    \n",
    "ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "\n",
    "# time span\n",
    "t_end = 400.\n",
    "t_span = (0.,t_end)\n",
    "\n",
    "sol = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "print(f'This should be around 0.85: {get_total_active_cases(sol)/total_population:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample epidemic curve: random initialization, delay = 50 days, 25% intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time span\n",
    "t_delay = 50.\n",
    "t_end = 200.\n",
    "t_span = (t_delay, t_end)\n",
    "\n",
    "# delayed initial conditions\n",
    "sol = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, (0.,t_delay), beta=beta) \n",
    "ini_cond_delay = sol[-1]\n",
    "\n",
    "# simulation\n",
    "sol_ni = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond_delay, t_span, beta=beta)\n",
    "sol_ui = Main.run_network_seir(Main.scipyCSC_to_julia(A_ui), ini_cond_delay, t_span, beta=beta)\n",
    "sol_hd = Main.run_network_seir(Main.scipyCSC_to_julia(A_hd), ini_cond_delay, t_span, beta=beta)\n",
    "sol_eg = Main.run_network_seir(Main.scipyCSC_to_julia(A_eg), ini_cond_delay, t_span, beta=beta)\n",
    "sol_sp = Main.run_network_seir(Main.scipyCSC_to_julia(A_sp), ini_cond_delay, t_span, beta=beta)\n",
    "sol_rw = Main.run_network_seir(Main.scipyCSC_to_julia(A_rw), ini_cond_delay, t_span, beta=beta)\n",
    "sol_lf50 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf50), ini_cond_delay, t_span, beta=beta)\n",
    "sol_lf10 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf10), ini_cond_delay, t_span, beta=beta)\n",
    "sol_lf02 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf02), ini_cond_delay, t_span, beta=beta)\n",
    "\n",
    "# get curves and make plot\n",
    "sum_s, sum_e, sum_i, sum_r = get_data_for_plotting(sol)\n",
    "sum_s_ni, sum_e_ni, sum_i_ni, sum_r_ni = get_data_for_plotting(sol_ni)\n",
    "sum_s_ui, sum_e_ui, sum_i_ui, sum_r_ui = get_data_for_plotting(sol_ui)\n",
    "sum_s_hd, sum_e_hd, sum_i_hd, sum_r_hd = get_data_for_plotting(sol_hd)\n",
    "sum_s_eg, sum_e_eg, sum_i_eg, sum_r_eg = get_data_for_plotting(sol_eg)\n",
    "sum_s_sp, sum_e_sp, sum_i_sp, sum_r_sp = get_data_for_plotting(sol_sp)\n",
    "sum_s_rw, sum_e_rw, sum_i_rw, sum_r_rw = get_data_for_plotting(sol_rw)\n",
    "sum_s_lf50, sum_e_lf50, sum_i_lf50, sum_r_lf50 = get_data_for_plotting(sol_lf50)\n",
    "sum_s_lf10, sum_e_lf10, sum_i_lf10, sum_r_lf10 = get_data_for_plotting(sol_lf10)\n",
    "sum_s_lf02, sum_e_lf02, sum_i_lf02, sum_r_lf02 = get_data_for_plotting(sol_lf02)\n",
    "\n",
    "t_ini = np.linspace(0, int(t_delay), num=int(t_delay)+1)\n",
    "t_int = np.linspace(t_delay, int(t_end), num=int(t_end-t_delay)+1)\n",
    "\n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(t_ini,(sum_e+sum_i)/total_population, linestyle='-', color='dimgray', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_ni+sum_i_ni)/total_population, label='NI', linestyle='-', color='dimgray', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_ui+sum_i_ui)/total_population, label='UI', linestyle=(0,(5,5)), color='k', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_eg+sum_i_eg)/total_population, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=4)\n",
    "plt.plot(t_int,(sum_e_hd+sum_i_hd)/total_population, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_sp+sum_i_sp)/total_population, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_rw+sum_i_rw)/total_population, label='CF', linestyle='dashed', color='tab:green', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf50+sum_i_lf50)/total_population, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf10+sum_i_lf10)/total_population, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=4)\n",
    "plt.plot(t_int,(sum_e_lf02+sum_i_lf02)/total_population, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=4)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks(size=18)\n",
    "plt.yticks((.0, .1), size=18)\n",
    "plt.xlabel('Day', fontsize=22)\n",
    "plt.ylabel('Active Cases',fontsize=22)\n",
    "plt.savefig(\"facebook_curves_randinit_85_delay50.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation for interventions that start on day 50, random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_weight = .1\n",
    "target_perc = [.05, .1, .15, .2, .25, .3, .35, .4, .45, .5]\n",
    "num_scenarios = len(target_perc)\n",
    "num_trials = 50\n",
    "\n",
    "maxCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "\n",
    "for k in range(num_scenarios):\n",
    "    \n",
    "    perc = target_perc[k]\n",
    "    A_ui = ((1-(1-reduced_weight)*perc)*nx.adjacency_matrix(G) + sp.sparse.eye(G.number_of_nodes())).tocsc()\n",
    "    A_hd = create_weighted_adjacency_from_degree_dist(G, perc, weight=reduced_weight)\n",
    "    A_eg = create_weighted_adjacency_from_node_betweenness(G, eigenvector_centrality, perc, weight=reduced_weight)\n",
    "    A_sp = create_weighted_adjacency_from_edge_betweenness(G, shortest_path_betweenness, perc, weight=reduced_weight)\n",
    "    A_rw = create_weighted_adjacency_from_edge_betweenness(G, current_flow_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf50 = create_weighted_adjacency_from_edge_betweenness(G, local50_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf10 = create_weighted_adjacency_from_edge_betweenness(G, local10_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf02 = create_weighted_adjacency_from_edge_betweenness(G, local02_betweenness, perc, weight=reduced_weight)\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        \n",
    "        print(f'perc = {perc:.2f}, trial {trial+1:d} of {num_trials}', end=\"\\n\")\n",
    "    \n",
    "        S_0 = np.zeros(n)\n",
    "        E_0 = np.zeros(n)\n",
    "        I_0 = np.zeros(n)\n",
    "        R_0 = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            S_0[i] = populations[map_to_original[i+1]]\n",
    "        \n",
    "        for i in sample(range(n),31):\n",
    "            E_0[i] = 0\n",
    "            I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "            S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "        \n",
    "        ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "        t_span = (0.,50.)\n",
    "        sol = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "        \n",
    "        ini_cond = sol[-1]\n",
    "        t_span = (0.,500.)\n",
    "        \n",
    "        sol_ni = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "        sol_ui = Main.run_network_seir(Main.scipyCSC_to_julia(A_ui), ini_cond, t_span, beta=beta)\n",
    "        sol_hd = Main.run_network_seir(Main.scipyCSC_to_julia(A_hd), ini_cond, t_span, beta=beta)\n",
    "        sol_eg = Main.run_network_seir(Main.scipyCSC_to_julia(A_eg), ini_cond, t_span, beta=beta)\n",
    "        sol_sp = Main.run_network_seir(Main.scipyCSC_to_julia(A_sp), ini_cond, t_span, beta=beta)\n",
    "        sol_rw = Main.run_network_seir(Main.scipyCSC_to_julia(A_rw), ini_cond, t_span, beta=beta)\n",
    "        sol_lf50 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf50), ini_cond, t_span, beta=beta)\n",
    "        sol_lf10 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf10), ini_cond, t_span, beta=beta)\n",
    "        sol_lf02 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf02), ini_cond, t_span, beta=beta) \n",
    "        maxCases_ni[trial,k] = get_max_active_cases(sol_ni)\n",
    "        maxCases_ui[trial,k] = get_max_active_cases(sol_ui)\n",
    "        maxCases_hd[trial,k] = get_max_active_cases(sol_hd)\n",
    "        maxCases_eg[trial,k] = get_max_active_cases(sol_eg)\n",
    "        maxCases_sp[trial,k] = get_max_active_cases(sol_sp)\n",
    "        maxCases_rw[trial,k] = get_max_active_cases(sol_rw)\n",
    "        maxCases_lf50[trial,k] = get_max_active_cases(sol_lf50)\n",
    "        maxCases_lf10[trial,k] = get_max_active_cases(sol_lf10)\n",
    "        maxCases_lf02[trial,k] = get_max_active_cases(sol_lf02)\n",
    "        totalCases_ni[trial,k] = get_total_active_cases(sol_ni)\n",
    "        totalCases_ui[trial,k] = get_total_active_cases(sol_ui)\n",
    "        totalCases_hd[trial,k] = get_total_active_cases(sol_hd)\n",
    "        totalCases_eg[trial,k] = get_total_active_cases(sol_eg)\n",
    "        totalCases_sp[trial,k] = get_total_active_cases(sol_sp)\n",
    "        totalCases_rw[trial,k] = get_total_active_cases(sol_rw)\n",
    "        totalCases_lf50[trial,k] = get_total_active_cases(sol_lf50)\n",
    "        totalCases_lf10[trial,k] = get_total_active_cases(sol_lf10)\n",
    "        totalCases_lf02[trial,k] = get_total_active_cases(sol_lf02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCases_ni_mean = np.mean(maxCases_ni/total_population, axis=0)\n",
    "maxCases_ui_mean = np.mean(maxCases_ui/total_population, axis=0)\n",
    "maxCases_hd_mean = np.mean(maxCases_hd/total_population, axis=0)\n",
    "maxCases_eg_mean = np.mean(maxCases_eg/total_population, axis=0)\n",
    "maxCases_sp_mean = np.mean(maxCases_sp/total_population, axis=0)\n",
    "maxCases_rw_mean = np.mean(maxCases_rw/total_population, axis=0)\n",
    "maxCases_lf50_mean = np.mean(maxCases_lf50/total_population, axis=0)\n",
    "maxCases_lf10_mean = np.mean(maxCases_lf10/total_population, axis=0)\n",
    "maxCases_lf02_mean = np.mean(maxCases_lf02/total_population, axis=0)\n",
    "totalCases_ni_mean = np.mean(totalCases_ni/total_population, axis=0)\n",
    "totalCases_ui_mean = np.mean(totalCases_ui/total_population, axis=0)\n",
    "totalCases_hd_mean = np.mean(totalCases_hd/total_population, axis=0)\n",
    "totalCases_eg_mean = np.mean(totalCases_eg/total_population, axis=0)\n",
    "totalCases_sp_mean = np.mean(totalCases_sp/total_population, axis=0)\n",
    "totalCases_rw_mean = np.mean(totalCases_rw/total_population, axis=0)\n",
    "totalCases_lf50_mean = np.mean(totalCases_lf50/total_population, axis=0)\n",
    "totalCases_lf10_mean = np.mean(totalCases_lf10/total_population, axis=0)\n",
    "totalCases_lf02_mean = np.mean(totalCases_lf02/total_population, axis=0)\n",
    "\n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, maxCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.1, .2, .3, .4, .5), ('$10\\%$', '$20\\%$', '$30\\%$', '$40\\%$', '$50\\%$'), color='k', size=18)\n",
    "plt.yticks((.1, .2), size=18)\n",
    "plt.xlabel('Percentage of Targeted Edges', fontsize=22)\n",
    "plt.ylabel('Epidemic Peak',fontsize=22)\n",
    "plt.savefig(\"facebook_epipeak_randinit_85_delay50.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()\n",
    "                                      \n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, totalCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.1, .2, .3, .4, .5), ('$10\\%$', '$20\\%$', '$30\\%$', '$40\\%$', '$50\\%$'), color='k', size=18)\n",
    "plt.yticks(size=18)\n",
    "plt.xlabel('Percentage of Targeted Edges', fontsize=22)\n",
    "plt.ylabel('Final Epidemic Size',fontsize=22)\n",
    "plt.savefig(\"facebook_episize_randinit_85_delay50.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2: 70% final size, random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=0.0236"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that $\\beta$ is set appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions\n",
    "S_0 = np.zeros(n)\n",
    "E_0 = np.zeros(n)\n",
    "I_0 = np.zeros(n)\n",
    "R_0 = np.zeros(n)\n",
    "for i in range(n):\n",
    "    S_0[i] = populations[map_to_original[i+1]] \n",
    "    \n",
    "# the following lines set up random initializatiom\n",
    "for i in sample(range(n),31):\n",
    "    E_0[i] = 0\n",
    "    I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "    S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "    \n",
    "ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "\n",
    "# time span\n",
    "t_end = 400.\n",
    "t_span = (0.,t_end)\n",
    "\n",
    "sol = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "print(f'This should be around 0.85: {get_total_active_cases(sol)/total_population:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample epidemic curve: random initialization,  25% intervention, no delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = .25\n",
    "reduced_weight = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ui = ((1-(1-reduced_weight)*perc)*nx.adjacency_matrix(G) + sp.sparse.eye(G.number_of_nodes())).tocsc()\n",
    "A_hd = create_weighted_adjacency_from_degree_dist(G, perc, weight=reduced_weight)\n",
    "A_eg = create_weighted_adjacency_from_node_betweenness(G, eigenvector_centrality, perc, weight=reduced_weight)\n",
    "A_sp = create_weighted_adjacency_from_edge_betweenness(G, shortest_path_betweenness, perc, weight=reduced_weight)\n",
    "A_rw = create_weighted_adjacency_from_edge_betweenness(G, current_flow_betweenness, perc, weight=reduced_weight)\n",
    "A_lf50 = create_weighted_adjacency_from_edge_betweenness(G, local50_betweenness, perc, weight=reduced_weight)\n",
    "A_lf10 = create_weighted_adjacency_from_edge_betweenness(G, local10_betweenness, perc, weight=reduced_weight)\n",
    "A_lf02 = create_weighted_adjacency_from_edge_betweenness(G, local02_betweenness, perc, weight=reduced_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time span\n",
    "t_end = 400.\n",
    "t_span = (0., t_end)\n",
    "\n",
    "# initial conditions\n",
    "n = G.number_of_nodes()\n",
    "S_0 = np.zeros(n)\n",
    "E_0 = np.zeros(n)\n",
    "I_0 = np.zeros(n)\n",
    "R_0 = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    S_0[i] = populations[map_to_original[i+1]]\n",
    "\n",
    "for i in sample(range(n),31):\n",
    "    E_0[i] = 0\n",
    "    I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "    S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\n",
    "ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "\n",
    "# simulation\n",
    "sol_ni = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "sol_ui = Main.run_network_seir(Main.scipyCSC_to_julia(A_ui), ini_cond, t_span, beta=beta)\n",
    "sol_hd = Main.run_network_seir(Main.scipyCSC_to_julia(A_hd), ini_cond, t_span, beta=beta)\n",
    "sol_eg = Main.run_network_seir(Main.scipyCSC_to_julia(A_eg), ini_cond, t_span, beta=beta)\n",
    "sol_sp = Main.run_network_seir(Main.scipyCSC_to_julia(A_sp), ini_cond, t_span, beta=beta)\n",
    "sol_rw = Main.run_network_seir(Main.scipyCSC_to_julia(A_rw), ini_cond, t_span, beta=beta)\n",
    "sol_lf50 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf50), ini_cond, t_span, beta=beta)\n",
    "sol_lf10 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf10), ini_cond, t_span, beta=beta)\n",
    "sol_lf02 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf02), ini_cond, t_span, beta=beta)\n",
    "\n",
    "# get curves and make plot\n",
    "sum_s_ni, sum_e_ni, sum_i_ni, sum_r_ni = get_data_for_plotting(sol_ni)\n",
    "sum_s_ui, sum_e_ui, sum_i_ui, sum_r_ui = get_data_for_plotting(sol_ui)\n",
    "sum_s_hd, sum_e_hd, sum_i_hd, sum_r_hd = get_data_for_plotting(sol_hd)\n",
    "sum_s_eg, sum_e_eg, sum_i_eg, sum_r_eg = get_data_for_plotting(sol_eg)\n",
    "sum_s_sp, sum_e_sp, sum_i_sp, sum_r_sp = get_data_for_plotting(sol_sp)\n",
    "sum_s_rw, sum_e_rw, sum_i_rw, sum_r_rw = get_data_for_plotting(sol_rw)\n",
    "sum_s_lf50, sum_e_lf50, sum_i_lf50, sum_r_lf50 = get_data_for_plotting(sol_lf50)\n",
    "sum_s_lf10, sum_e_lf10, sum_i_lf10, sum_r_lf10 = get_data_for_plotting(sol_lf10)\n",
    "sum_s_lf02, sum_e_lf02, sum_i_lf02, sum_r_lf02 = get_data_for_plotting(sol_lf02)\n",
    "\n",
    "t_int = np.linspace(0, int(t_end), num=int(t_end)+1)\n",
    "\n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(t_int,(sum_e_ni+sum_i_ni)/total_population, label='NI', linestyle='-', color='dimgray', linewidth=3, alpha=1)\n",
    "plt.plot(t_int,(sum_e_ui+sum_i_ui)/total_population, label='UI', linestyle=(0,(5,5)), color='k', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_eg+sum_i_eg)/total_population, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_hd+sum_i_hd)/total_population, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_sp+sum_i_sp)/total_population, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_rw+sum_i_rw)/total_population, label='CF', linestyle='dashed', color='tab:green', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf50+sum_i_lf50)/total_population, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf10+sum_i_lf10)/total_population, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf02+sum_i_lf02)/total_population, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=4)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks(size=18)\n",
    "plt.yticks((.0, .1), size=18)\n",
    "plt.xlabel('Day', fontsize=22)\n",
    "plt.ylabel('Active Cases',fontsize=22)\n",
    "plt.savefig(\"facebook_curves_randinit_70.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation for interventions that start on day 0, random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_weight = .1\n",
    "target_perc = [.05, .1, .15, .2, .25, .3, .35, .4, .45, .5]\n",
    "num_scenarios = len(target_perc)\n",
    "num_trials = 50\n",
    "\n",
    "maxCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "\n",
    "for k in range(num_scenarios):\n",
    "    \n",
    "    perc = target_perc[k]\n",
    "    A_ui = ((1-(1-reduced_weight)*perc)*nx.adjacency_matrix(G) + sp.sparse.eye(G.number_of_nodes())).tocsc()\n",
    "    A_hd = create_weighted_adjacency_from_degree_dist(G, perc, weight=reduced_weight)\n",
    "    A_eg = create_weighted_adjacency_from_node_betweenness(G, eigenvector_centrality, perc, weight=reduced_weight)\n",
    "    A_sp = create_weighted_adjacency_from_edge_betweenness(G, shortest_path_betweenness, perc, weight=reduced_weight)\n",
    "    A_rw = create_weighted_adjacency_from_edge_betweenness(G, current_flow_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf50 = create_weighted_adjacency_from_edge_betweenness(G, local50_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf10 = create_weighted_adjacency_from_edge_betweenness(G, local10_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf02 = create_weighted_adjacency_from_edge_betweenness(G, local02_betweenness, perc, weight=reduced_weight)\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        \n",
    "        print(f'perc = {perc:.2f}, trial {trial+1:d} of {num_trials:d}', end=\"\\n\")\n",
    "    \n",
    "        S_0 = np.zeros(n)\n",
    "        E_0 = np.zeros(n)\n",
    "        I_0 = np.zeros(n)\n",
    "        R_0 = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            S_0[i] = populations[map_to_original[i+1]]\n",
    "\n",
    "        for i in sample(range(n),31):\n",
    "            E_0[i] = 0\n",
    "            I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "            S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\n",
    "        ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "        t_span = (0.,1200.)\n",
    "        \n",
    "        sol_ni = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "        sol_ui = Main.run_network_seir(Main.scipyCSC_to_julia(A_ui), ini_cond, t_span, beta=beta)\n",
    "        sol_hd = Main.run_network_seir(Main.scipyCSC_to_julia(A_hd), ini_cond, t_span, beta=beta)\n",
    "        sol_eg = Main.run_network_seir(Main.scipyCSC_to_julia(A_eg), ini_cond, t_span, beta=beta)\n",
    "        sol_sp = Main.run_network_seir(Main.scipyCSC_to_julia(A_sp), ini_cond, t_span, beta=beta)\n",
    "        sol_rw = Main.run_network_seir(Main.scipyCSC_to_julia(A_rw), ini_cond, t_span, beta=beta)\n",
    "        sol_lf50 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf50), ini_cond, t_span, beta=beta)\n",
    "        sol_lf10 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf10), ini_cond, t_span, beta=beta)\n",
    "        sol_lf02 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf02), ini_cond, t_span, beta=beta) \n",
    "        maxCases_ni[trial,k] = get_max_active_cases(sol_ni)\n",
    "        maxCases_ui[trial,k] = get_max_active_cases(sol_ui)\n",
    "        maxCases_hd[trial,k] = get_max_active_cases(sol_hd)\n",
    "        maxCases_eg[trial,k] = get_max_active_cases(sol_eg)\n",
    "        maxCases_sp[trial,k] = get_max_active_cases(sol_sp)\n",
    "        maxCases_rw[trial,k] = get_max_active_cases(sol_rw)\n",
    "        maxCases_lf50[trial,k] = get_max_active_cases(sol_lf50)\n",
    "        maxCases_lf10[trial,k] = get_max_active_cases(sol_lf10)\n",
    "        maxCases_lf02[trial,k] = get_max_active_cases(sol_lf02)\n",
    "        totalCases_ni[trial,k] = get_total_active_cases(sol_ni)\n",
    "        totalCases_ui[trial,k] = get_total_active_cases(sol_ui)\n",
    "        totalCases_hd[trial,k] = get_total_active_cases(sol_hd)\n",
    "        totalCases_eg[trial,k] = get_total_active_cases(sol_eg)\n",
    "        totalCases_sp[trial,k] = get_total_active_cases(sol_sp)\n",
    "        totalCases_rw[trial,k] = get_total_active_cases(sol_rw)\n",
    "        totalCases_lf50[trial,k] = get_total_active_cases(sol_lf50)\n",
    "        totalCases_lf10[trial,k] = get_total_active_cases(sol_lf10)\n",
    "        totalCases_lf02[trial,k] = get_total_active_cases(sol_lf02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCases_ni_mean = np.mean(maxCases_ni/total_population, axis=0)\n",
    "maxCases_ui_mean = np.mean(maxCases_ui/total_population, axis=0)\n",
    "maxCases_hd_mean = np.mean(maxCases_hd/total_population, axis=0)\n",
    "maxCases_eg_mean = np.mean(maxCases_eg/total_population, axis=0)\n",
    "maxCases_sp_mean = np.mean(maxCases_sp/total_population, axis=0)\n",
    "maxCases_rw_mean = np.mean(maxCases_rw/total_population, axis=0)\n",
    "maxCases_lf50_mean = np.mean(maxCases_lf50/total_population, axis=0)\n",
    "maxCases_lf10_mean = np.mean(maxCases_lf10/total_population, axis=0)\n",
    "maxCases_lf02_mean = np.mean(maxCases_lf02/total_population, axis=0)\n",
    "totalCases_ni_mean = np.mean(totalCases_ni/total_population, axis=0)\n",
    "totalCases_ui_mean = np.mean(totalCases_ui/total_population, axis=0)\n",
    "totalCases_hd_mean = np.mean(totalCases_hd/total_population, axis=0)\n",
    "totalCases_eg_mean = np.mean(totalCases_eg/total_population, axis=0)\n",
    "totalCases_sp_mean = np.mean(totalCases_sp/total_population, axis=0)\n",
    "totalCases_rw_mean = np.mean(totalCases_rw/total_population, axis=0)\n",
    "totalCases_lf50_mean = np.mean(totalCases_lf50/total_population, axis=0)\n",
    "totalCases_lf10_mean = np.mean(totalCases_lf10/total_population, axis=0)\n",
    "totalCases_lf02_mean = np.mean(totalCases_lf02/total_population, axis=0)\n",
    "\n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, maxCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.1, .2, .3, .4, .5), ('$10\\%$', '$20\\%$', '$30\\%$', '$40\\%$', '$50\\%$'), color='k', size=18)\n",
    "plt.yticks((.0, .1), size=18)\n",
    "plt.xlabel('Percentage of Targeted Edges', fontsize=22)\n",
    "plt.ylabel('Epidemic Peak',fontsize=22)\n",
    "plt.savefig(\"facebook_epipeak_randinit_70.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()\n",
    "                                      \n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, totalCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.1, .2, .3, .4, .5), ('$10\\%$', '$20\\%$', '$30\\%$', '$40\\%$', '$50\\%$'), color='k', size=18)\n",
    "plt.yticks(size=18)\n",
    "plt.xlabel('Percentage of Targeted Edges', fontsize=22)\n",
    "plt.ylabel('Final Epidemic Size',fontsize=22)\n",
    "plt.savefig(\"facebook_episize_randinit_70.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3: $\\beta$ is set to give 55% final size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=0.0195"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that $\\beta$ is set appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions\n",
    "S_0 = np.zeros(n)\n",
    "E_0 = np.zeros(n)\n",
    "I_0 = np.zeros(n)\n",
    "R_0 = np.zeros(n)\n",
    "for i in range(n):\n",
    "    S_0[i] = populations[map_to_original[i+1]] \n",
    "    \n",
    "# the following lines set up random initializatiom\n",
    "for i in sample(range(n),31):\n",
    "    E_0[i] = 0\n",
    "    I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "    S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "    \n",
    "ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "\n",
    "# time span\n",
    "t_end = 400.\n",
    "t_span = (0.,t_end)\n",
    "\n",
    "sol = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "print(f'This should be around 0.50: {get_total_active_cases(sol)/total_population:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample epidemic curve: random initialization, 25% intervention, no delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = .25\n",
    "reduced_weight = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ui = ((1-(1-reduced_weight)*perc)*nx.adjacency_matrix(G) + sp.sparse.eye(G.number_of_nodes())).tocsc()\n",
    "A_hd = create_weighted_adjacency_from_degree_dist(G, perc, weight=reduced_weight)\n",
    "A_eg = create_weighted_adjacency_from_node_betweenness(G, eigenvector_centrality, perc, weight=reduced_weight)\n",
    "A_sp = create_weighted_adjacency_from_edge_betweenness(G, shortest_path_betweenness, perc, weight=reduced_weight)\n",
    "A_rw = create_weighted_adjacency_from_edge_betweenness(G, current_flow_betweenness, perc, weight=reduced_weight)\n",
    "A_lf50 = create_weighted_adjacency_from_edge_betweenness(G, local50_betweenness, perc, weight=reduced_weight)\n",
    "A_lf10 = create_weighted_adjacency_from_edge_betweenness(G, local10_betweenness, perc, weight=reduced_weight)\n",
    "A_lf02 = create_weighted_adjacency_from_edge_betweenness(G, local02_betweenness, perc, weight=reduced_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time span\n",
    "t_end = 500.\n",
    "t_span = (0., t_end)\n",
    "\n",
    "# initial conditions\n",
    "n = G.number_of_nodes()\n",
    "S_0 = np.zeros(n)\n",
    "E_0 = np.zeros(n)\n",
    "I_0 = np.zeros(n)\n",
    "R_0 = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    S_0[i] = populations[map_to_original[i+1]]\n",
    "\n",
    "for i in sample(range(n),31):\n",
    "    E_0[i] = 0\n",
    "    I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "    S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\n",
    "ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "\n",
    "# simulation\n",
    "sol_ni = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "sol_ui = Main.run_network_seir(Main.scipyCSC_to_julia(A_ui), ini_cond, t_span, beta=beta)\n",
    "sol_hd = Main.run_network_seir(Main.scipyCSC_to_julia(A_hd), ini_cond, t_span, beta=beta)\n",
    "sol_eg = Main.run_network_seir(Main.scipyCSC_to_julia(A_eg), ini_cond, t_span, beta=beta)\n",
    "sol_sp = Main.run_network_seir(Main.scipyCSC_to_julia(A_sp), ini_cond, t_span, beta=beta)\n",
    "sol_rw = Main.run_network_seir(Main.scipyCSC_to_julia(A_rw), ini_cond, t_span, beta=beta)\n",
    "sol_lf50 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf50), ini_cond, t_span, beta=beta)\n",
    "sol_lf10 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf10), ini_cond, t_span, beta=beta)\n",
    "sol_lf02 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf02), ini_cond, t_span, beta=beta)\n",
    "\n",
    "# get curves and make plot\n",
    "sum_s_ni, sum_e_ni, sum_i_ni, sum_r_ni = get_data_for_plotting(sol_ni)\n",
    "sum_s_ui, sum_e_ui, sum_i_ui, sum_r_ui = get_data_for_plotting(sol_ui)\n",
    "sum_s_hd, sum_e_hd, sum_i_hd, sum_r_hd = get_data_for_plotting(sol_hd)\n",
    "sum_s_eg, sum_e_eg, sum_i_eg, sum_r_eg = get_data_for_plotting(sol_eg)\n",
    "sum_s_sp, sum_e_sp, sum_i_sp, sum_r_sp = get_data_for_plotting(sol_sp)\n",
    "sum_s_rw, sum_e_rw, sum_i_rw, sum_r_rw = get_data_for_plotting(sol_rw)\n",
    "sum_s_lf50, sum_e_lf50, sum_i_lf50, sum_r_lf50 = get_data_for_plotting(sol_lf50)\n",
    "sum_s_lf10, sum_e_lf10, sum_i_lf10, sum_r_lf10 = get_data_for_plotting(sol_lf10)\n",
    "sum_s_lf02, sum_e_lf02, sum_i_lf02, sum_r_lf02 = get_data_for_plotting(sol_lf02)\n",
    "\n",
    "t_int = np.linspace(0, int(t_end), num=int(t_end)+1)\n",
    "\n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(t_int,(sum_e_ni+sum_i_ni)/total_population, label='NI', linestyle='-', color='dimgray', linewidth=3, alpha=1)\n",
    "plt.plot(t_int,(sum_e_ui+sum_i_ui)/total_population, label='UI', linestyle=(0,(5,5)), color='k', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_eg+sum_i_eg)/total_population, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_hd+sum_i_hd)/total_population, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_sp+sum_i_sp)/total_population, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_rw+sum_i_rw)/total_population, label='CF', linestyle='dashed', color='tab:green', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf50+sum_i_lf50)/total_population, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf10+sum_i_lf10)/total_population, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=4, alpha=1)\n",
    "plt.plot(t_int,(sum_e_lf02+sum_i_lf02)/total_population, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=4)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks(size=18)\n",
    "plt.yticks(size=18)\n",
    "plt.xlabel('Day', fontsize=22)\n",
    "plt.ylabel('Active Cases',fontsize=22)\n",
    "plt.savefig(\"facebook_curves_randinit_55.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation for interventions that start on day 0, random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_weight = .1\n",
    "target_perc = [.05, .1, .15, .2, .25, .3, .35, .4, .45, .5]\n",
    "num_scenarios = len(target_perc)\n",
    "num_trials = 50\n",
    "\n",
    "maxCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "\n",
    "for k in range(num_scenarios):\n",
    "    \n",
    "    perc = target_perc[k]\n",
    "    A_ui = ((1-(1-reduced_weight)*perc)*nx.adjacency_matrix(G) + sp.sparse.eye(G.number_of_nodes())).tocsc()\n",
    "    A_hd = create_weighted_adjacency_from_degree_dist(G, perc, weight=reduced_weight)\n",
    "    A_eg = create_weighted_adjacency_from_node_betweenness(G, eigenvector_centrality, perc, weight=reduced_weight)\n",
    "    A_sp = create_weighted_adjacency_from_edge_betweenness(G, shortest_path_betweenness, perc, weight=reduced_weight)\n",
    "    A_rw = create_weighted_adjacency_from_edge_betweenness(G, current_flow_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf50 = create_weighted_adjacency_from_edge_betweenness(G, local50_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf10 = create_weighted_adjacency_from_edge_betweenness(G, local10_betweenness, perc, weight=reduced_weight)\n",
    "    A_lf02 = create_weighted_adjacency_from_edge_betweenness(G, local02_betweenness, perc, weight=reduced_weight)\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        \n",
    "        print(f'perc = {perc:.2f}, trial {trial+1:d} of {num_trials:d}', end=\"\\n\")\n",
    "    \n",
    "        S_0 = np.zeros(n)\n",
    "        E_0 = np.zeros(n)\n",
    "        I_0 = np.zeros(n)\n",
    "        R_0 = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            S_0[i] = populations[map_to_original[i+1]]\n",
    "\n",
    "        for i in sample(range(n),31):\n",
    "            E_0[i] = 0\n",
    "            I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "            S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\n",
    "        ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "        t_span = (0.,1500.)\n",
    "        \n",
    "        sol_ni = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "        sol_ui = Main.run_network_seir(Main.scipyCSC_to_julia(A_ui), ini_cond, t_span, beta=beta)\n",
    "        sol_hd = Main.run_network_seir(Main.scipyCSC_to_julia(A_hd), ini_cond, t_span, beta=beta)\n",
    "        sol_eg = Main.run_network_seir(Main.scipyCSC_to_julia(A_eg), ini_cond, t_span, beta=beta)\n",
    "        sol_sp = Main.run_network_seir(Main.scipyCSC_to_julia(A_sp), ini_cond, t_span, beta=beta)\n",
    "        sol_rw = Main.run_network_seir(Main.scipyCSC_to_julia(A_rw), ini_cond, t_span, beta=beta)\n",
    "        sol_lf50 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf50), ini_cond, t_span, beta=beta)\n",
    "        sol_lf10 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf10), ini_cond, t_span, beta=beta)\n",
    "        sol_lf02 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf02), ini_cond, t_span, beta=beta) \n",
    "        maxCases_ni[trial,k] = get_max_active_cases(sol_ni)\n",
    "        maxCases_ui[trial,k] = get_max_active_cases(sol_ui)\n",
    "        maxCases_hd[trial,k] = get_max_active_cases(sol_hd)\n",
    "        maxCases_eg[trial,k] = get_max_active_cases(sol_eg)\n",
    "        maxCases_sp[trial,k] = get_max_active_cases(sol_sp)\n",
    "        maxCases_rw[trial,k] = get_max_active_cases(sol_rw)\n",
    "        maxCases_lf50[trial,k] = get_max_active_cases(sol_lf50)\n",
    "        maxCases_lf10[trial,k] = get_max_active_cases(sol_lf10)\n",
    "        maxCases_lf02[trial,k] = get_max_active_cases(sol_lf02)\n",
    "        totalCases_ni[trial,k] = get_total_active_cases(sol_ni)\n",
    "        totalCases_ui[trial,k] = get_total_active_cases(sol_ui)\n",
    "        totalCases_hd[trial,k] = get_total_active_cases(sol_hd)\n",
    "        totalCases_eg[trial,k] = get_total_active_cases(sol_eg)\n",
    "        totalCases_sp[trial,k] = get_total_active_cases(sol_sp)\n",
    "        totalCases_rw[trial,k] = get_total_active_cases(sol_rw)\n",
    "        totalCases_lf50[trial,k] = get_total_active_cases(sol_lf50)\n",
    "        totalCases_lf10[trial,k] = get_total_active_cases(sol_lf10)\n",
    "        totalCases_lf02[trial,k] = get_total_active_cases(sol_lf02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCases_ni_mean = np.mean(maxCases_ni/total_population, axis=0)\n",
    "maxCases_ui_mean = np.mean(maxCases_ui/total_population, axis=0)\n",
    "maxCases_hd_mean = np.mean(maxCases_hd/total_population, axis=0)\n",
    "maxCases_eg_mean = np.mean(maxCases_eg/total_population, axis=0)\n",
    "maxCases_sp_mean = np.mean(maxCases_sp/total_population, axis=0)\n",
    "maxCases_rw_mean = np.mean(maxCases_rw/total_population, axis=0)\n",
    "maxCases_lf50_mean = np.mean(maxCases_lf50/total_population, axis=0)\n",
    "maxCases_lf10_mean = np.mean(maxCases_lf10/total_population, axis=0)\n",
    "maxCases_lf02_mean = np.mean(maxCases_lf02/total_population, axis=0)\n",
    "totalCases_ni_mean = np.mean(totalCases_ni/total_population, axis=0)\n",
    "totalCases_ui_mean = np.mean(totalCases_ui/total_population, axis=0)\n",
    "totalCases_hd_mean = np.mean(totalCases_hd/total_population, axis=0)\n",
    "totalCases_eg_mean = np.mean(totalCases_eg/total_population, axis=0)\n",
    "totalCases_sp_mean = np.mean(totalCases_sp/total_population, axis=0)\n",
    "totalCases_rw_mean = np.mean(totalCases_rw/total_population, axis=0)\n",
    "totalCases_lf50_mean = np.mean(totalCases_lf50/total_population, axis=0)\n",
    "totalCases_lf10_mean = np.mean(totalCases_lf10/total_population, axis=0)\n",
    "totalCases_lf02_mean = np.mean(totalCases_lf02/total_population, axis=0)\n",
    "\n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, maxCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.1, .2, .3, .4, .5), ('$10\\%$', '$20\\%$', '$30\\%$', '$40\\%$', '$50\\%$'), color='k', size=18)\n",
    "plt.yticks(size=18)\n",
    "plt.xlabel('Percentage of Targeted Edges', fontsize=22)\n",
    "plt.ylabel('Epidemic Peak',fontsize=22)\n",
    "plt.savefig(\"facebook_epipeak_randinit_55.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()\n",
    "                                      \n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, totalCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.1, .2, .3, .4, .5), ('$10\\%$', '$20\\%$', '$30\\%$', '$40\\%$', '$50\\%$'), color='k', size=18)\n",
    "plt.yticks(size=18)\n",
    "plt.xlabel('Percentage of Targeted Edges', fontsize=22)\n",
    "plt.ylabel('Final Epidemic Size',fontsize=22)\n",
    "plt.savefig(\"facebook_episize_randinit_55.tiff\", bbox_inches='tight', format='tiff', dpi=400, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node immunization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that $\\beta$ is set appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions\n",
    "S_0 = np.zeros(n)\n",
    "E_0 = np.zeros(n)\n",
    "I_0 = np.zeros(n)\n",
    "R_0 = np.zeros(n)\n",
    "for i in range(n):\n",
    "    S_0[i] = populations[map_to_original[i+1]]\n",
    "\n",
    "for i in sample(range(n),31):\n",
    "    E_0[i] = 0\n",
    "    I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "    S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "    \n",
    "ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "\n",
    "# time span\n",
    "t_end = 400.\n",
    "t_span = (0.,t_end)\n",
    "\n",
    "sol = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "print(f'This should be around 0.85: {get_total_active_cases(sol)/total_population:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_sp = edge_to_node_betweenness(shortest_path_betweenness, G.nodes())\n",
    "node_rw = edge_to_node_betweenness(current_flow_betweenness, G.nodes())\n",
    "node_lf50 = edge_to_node_betweenness(local50_betweenness, G.nodes())\n",
    "node_lf10 = edge_to_node_betweenness(local10_betweenness, G.nodes())\n",
    "node_lf02 = edge_to_node_betweenness(local02_betweenness, G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_weight = 0\n",
    "target_perc = [.05, .1, .15, .2, .25, .3]\n",
    "num_scenarios = len(target_perc)\n",
    "num_trials = 50\n",
    "\n",
    "maxCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "maxCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ni = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_ui = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_hd = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_eg = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_sp = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_rw = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf50 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf10 = np.zeros((num_trials,num_scenarios))\n",
    "totalCases_lf02 = np.zeros((num_trials,num_scenarios))\n",
    "\n",
    "for k in range(num_scenarios):\n",
    "    \n",
    "    perc = target_perc[k]\n",
    "    A_ui = create_weighted_adjacency_target_random_nodes(G, perc, weight=reduced_weight)\n",
    "    A_hd = create_weighted_adjacency_from_degree_dist_target_nodes(G, perc, weight=reduced_weight)\n",
    "    A_eg = create_weighted_adjacency_from_node_betweenness_target_nodes(G, eigenvector_centrality, perc, weight=reduced_weight)\n",
    "    A_sp = create_weighted_adjacency_from_node_betweenness_target_nodes(G, node_sp, perc, weight=reduced_weight)\n",
    "    A_rw = create_weighted_adjacency_from_node_betweenness_target_nodes(G, node_rw, perc, weight=reduced_weight)\n",
    "    A_lf50 = create_weighted_adjacency_from_node_betweenness_target_nodes(G, node_lf50, perc, weight=reduced_weight)\n",
    "    A_lf10 = create_weighted_adjacency_from_node_betweenness_target_nodes(G, node_lf10, perc, weight=reduced_weight)\n",
    "    A_lf02 = create_weighted_adjacency_from_node_betweenness_target_nodes(G, node_lf02, perc, weight=reduced_weight)\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        \n",
    "        print(f'perc = {perc:.2f}, trial {trial+1:d} of {num_trials:d}', end=\"\\n\")\n",
    "    \n",
    "        S_0 = np.zeros(n)\n",
    "        E_0 = np.zeros(n)\n",
    "        I_0 = np.zeros(n)\n",
    "        R_0 = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            S_0[i] = populations[map_to_original[i+1]]\n",
    "        for i in sample(range(n),31):\n",
    "            E_0[i] = 0\n",
    "            I_0[i] = populations[map_to_original[i+1]] * .001\n",
    "            S_0[i] = S_0[i] - E_0[i] - I_0[i]\n",
    "\n",
    "        ini_cond = np.column_stack((S_0,E_0,I_0,R_0))\n",
    "        t_span = (0.,1000.)\n",
    "        \n",
    "        sol_ni = Main.run_network_seir(Main.scipyCSC_to_julia(A), ini_cond, t_span, beta=beta)\n",
    "        sol_ui = Main.run_network_seir(Main.scipyCSC_to_julia(A_ui), ini_cond, t_span, beta=beta)\n",
    "        sol_hd = Main.run_network_seir(Main.scipyCSC_to_julia(A_hd), ini_cond, t_span, beta=beta)\n",
    "        sol_eg = Main.run_network_seir(Main.scipyCSC_to_julia(A_eg), ini_cond, t_span, beta=beta)\n",
    "        sol_sp = Main.run_network_seir(Main.scipyCSC_to_julia(A_sp), ini_cond, t_span, beta=beta)\n",
    "        sol_rw = Main.run_network_seir(Main.scipyCSC_to_julia(A_rw), ini_cond, t_span, beta=beta)\n",
    "        sol_lf50 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf50), ini_cond, t_span, beta=beta)\n",
    "        sol_lf10 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf10), ini_cond, t_span, beta=beta)\n",
    "        sol_lf02 = Main.run_network_seir(Main.scipyCSC_to_julia(A_lf02), ini_cond, t_span, beta=beta) \n",
    "        maxCases_ni[trial,k] = get_max_active_cases(sol_ni)\n",
    "        maxCases_ui[trial,k] = get_max_active_cases(sol_ui)\n",
    "        maxCases_hd[trial,k] = get_max_active_cases(sol_hd)\n",
    "        maxCases_eg[trial,k] = get_max_active_cases(sol_eg)\n",
    "        maxCases_sp[trial,k] = get_max_active_cases(sol_sp)\n",
    "        maxCases_rw[trial,k] = get_max_active_cases(sol_rw)\n",
    "        maxCases_lf50[trial,k] = get_max_active_cases(sol_lf50)\n",
    "        maxCases_lf10[trial,k] = get_max_active_cases(sol_lf10)\n",
    "        maxCases_lf02[trial,k] = get_max_active_cases(sol_lf02)\n",
    "        totalCases_ni[trial,k] = get_total_active_cases(sol_ni)\n",
    "        totalCases_ui[trial,k] = get_total_active_cases(sol_ui)\n",
    "        totalCases_hd[trial,k] = get_total_active_cases(sol_hd)\n",
    "        totalCases_eg[trial,k] = get_total_active_cases(sol_eg)\n",
    "        totalCases_sp[trial,k] = get_total_active_cases(sol_sp)\n",
    "        totalCases_rw[trial,k] = get_total_active_cases(sol_rw)\n",
    "        totalCases_lf50[trial,k] = get_total_active_cases(sol_lf50)\n",
    "        totalCases_lf10[trial,k] = get_total_active_cases(sol_lf10)\n",
    "        totalCases_lf02[trial,k] = get_total_active_cases(sol_lf02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCases_ni_mean = np.mean(maxCases_ni/total_population, axis=0)\n",
    "maxCases_ui_mean = np.mean(maxCases_ui/total_population, axis=0)\n",
    "maxCases_hd_mean = np.mean(maxCases_hd/total_population, axis=0)\n",
    "maxCases_eg_mean = np.mean(maxCases_eg/total_population, axis=0)\n",
    "maxCases_sp_mean = np.mean(maxCases_sp/total_population, axis=0)\n",
    "maxCases_rw_mean = np.mean(maxCases_rw/total_population, axis=0)\n",
    "maxCases_lf50_mean = np.mean(maxCases_lf50/total_population, axis=0)\n",
    "maxCases_lf10_mean = np.mean(maxCases_lf10/total_population, axis=0)\n",
    "maxCases_lf02_mean = np.mean(maxCases_lf02/total_population, axis=0)\n",
    "totalCases_ni_mean = np.mean(totalCases_ni/total_population, axis=0)\n",
    "totalCases_ui_mean = np.mean(totalCases_ui/total_population, axis=0)\n",
    "totalCases_hd_mean = np.mean(totalCases_hd/total_population, axis=0)\n",
    "totalCases_eg_mean = np.mean(totalCases_eg/total_population, axis=0)\n",
    "totalCases_sp_mean = np.mean(totalCases_sp/total_population, axis=0)\n",
    "totalCases_rw_mean = np.mean(totalCases_rw/total_population, axis=0)\n",
    "totalCases_lf50_mean = np.mean(totalCases_lf50/total_population, axis=0)\n",
    "totalCases_lf10_mean = np.mean(totalCases_lf10/total_population, axis=0)\n",
    "totalCases_lf02_mean = np.mean(totalCases_lf02/total_population, axis=0)\n",
    "\n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, maxCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, maxCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.05, .1, .15, .2, .25, .3), ('$5\\%$', '$10\\%$', '$15\\%$', '$20\\%$', '$25\\%$', '$30\\%$'), color='k', size=18)\n",
    "plt.yticks( size=18)\n",
    "plt.xlabel('Percentage of Targeted Nodes', fontsize=22)\n",
    "plt.ylabel('Epidemic Peak',fontsize=22)\n",
    "plt.savefig(\"facebook_epipeak_randinit_85_immu.png\", bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "                                      \n",
    "plt.figure(figsize=(9.3,4.5))\n",
    "plt.plot(target_perc, totalCases_ni_mean, label='NI', linestyle='-', color='dimgray', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_ui_mean, label='UI', linestyle=(0,(5,5)), color='k', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_hd_mean, label='HD', linestyle=(0,(3,5,1,5)), color='tab:red', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_eg_mean, label='EG', linestyle=(0,(3,1,1,1)), color='tab:brown', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_sp_mean, label='SP', linestyle=(0,(5,1)), color='tab:orange', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_rw_mean, label='CF', linestyle='dashed', color='tab:green', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf50_mean, label='LF(1/2)', linestyle=(0,(1,1)), color=\"tab:cyan\", linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf10_mean, label='LF(1/10)', linestyle=(0,(3,1,1,1,1,1)), color='tab:purple', linewidth=6)\n",
    "plt.plot(target_perc, totalCases_lf02_mean, label='LF(1/50)', linestyle='dashdot', color='tab:blue', linewidth=6)\n",
    "leg = plt.legend(fontsize=18, bbox_to_anchor=(.5, 1.4), ncol=3, loc='upper center', handlelength=4)\n",
    "for i in leg.legendHandles:\n",
    "    i.set_linewidth(4)\n",
    "plt.xticks((.05, .1, .15, .2, .25, .3), ('$5\\%$', '$10\\%$', '$15\\%$', '$20\\%$', '$25\\%$', '$30\\%$'), color='k', size=18)\n",
    "plt.yticks(size=18)\n",
    "plt.xlabel('Percentage of Targeted Nodes', fontsize=22)\n",
    "plt.ylabel('Final Epidemic Size',fontsize=22)\n",
    "plt.savefig(\"facebook_episize_randinit_85_immu.png\", bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
